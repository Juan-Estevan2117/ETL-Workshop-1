{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92fe863",
   "metadata": {},
   "source": [
    "# **EDA - Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b53bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pycountry\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path # manage paths for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path of the data\n",
    "data_path = Path('..') / 'data' / 'raw' / 'candidates.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f0fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first trouble, the data is not separated by comma, instead, it is separated \n",
    "# by semicolon so, the argument (sep='<separator>') allows indicate to pandas \n",
    "# the separation method\n",
    "\n",
    "df_candidates_org = pd.read_csv(data_path, sep=';')\n",
    "df_candidates_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9475352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates_org.info()\n",
    "\n",
    "# No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d601142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy for temporal transformations\n",
    "\n",
    "df_candidates = df_candidates_org.copy()\n",
    "df_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make easier the EDA process, all str values in df (including columns \n",
    "# names) were changed for their lowercase version \n",
    "\n",
    "df_candidates.columns = df_candidates.columns.str.lower()\n",
    "df_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe041a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_colummns = df_candidates.select_dtypes(include=['object', \n",
    "                                                    'string']).columns\n",
    "\n",
    "for column in text_colummns:\n",
    "    if column != \"email\":\n",
    "        df_candidates[column] = df_candidates[column].str.lower()\n",
    "    \n",
    "df_candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633bdf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates.describe()\n",
    "\n",
    "# Numerical values dont show out of range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd823bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To confirm that the numerical values are within expected ranges and \n",
    "# understand their distribution, we plot histograms. The almost uniform \n",
    "# distribution of scores suggests the data might be synthetically generated.\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.histplot(df_candidates[\"yoe\"], \n",
    "            bins=15, ax=axes[0], \n",
    "            color=\"skyblue\").set_title(\"Distribution of YOE\")\n",
    "sns.histplot(df_candidates[\"code challenge score\"], \n",
    "            bins=10, ax=axes[1], \n",
    "            color=\"lightgreen\").set_title(\"Code Challenge Score\")\n",
    "sns.histplot(df_candidates[\"technical interview score\"], bins=10, ax=axes[2], \n",
    "            color=\"salmon\").set_title(\"Technical Interview Score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, in necessary verify the unique values for de categorical columns \n",
    "\n",
    "df_candidates[\"email\"].unique()\n",
    "\n",
    "# The “length” section indicates that only 49,833 records are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ba057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To decide what to do, it will be investigated whether these are data errors \n",
    "# or whether the context of the problem allows it \n",
    "\n",
    "# filter which columns that had emails duplicated\n",
    "df_duplicated = df_candidates[df_candidates.duplicated(subset= [\"email\"])] \n",
    "df_duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ea714",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_emails = df_duplicated[\"email\"].values\n",
    "print(duplicated_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d9b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this celd if you wanna see all records\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this celd if you dont wanna see all records\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf50cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates[df_candidates[\"email\"].isin(duplicated_emails)].sort_values(\n",
    "                                                                by=\"email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec977c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While it is true that other contact details (such as a phone number) could \n",
    "# be used to uniquely identify a candidate, the fact that the same email \n",
    "# address is associated with more than one person, from a data quality \n",
    "# perspective, would pose a risk to the reliability of that data. This could \n",
    "# be due to fraud or identity theft, an error in the data collection system \n",
    "# (such as a faulty web form), or corrupted data at source. Doubtful data s\n",
    "# hould not be entered into the data warehouse. Therefore, all records with the\n",
    "# same email address will be deleted.\n",
    "\n",
    "df_candidates.drop_duplicates(subset=['email'], keep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d7230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the date range\n",
    "\n",
    "print(f\"fecha inicial: {df_candidates['application date'].min()}\")\n",
    "print(f\"fecha final: {df_candidates['application date'].max()}\")\n",
    "\n",
    "# Theres no dates out of range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b84e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates[\"country\"].unique()\n",
    "\n",
    "# 244 unique countries were identified, which exceeds the 195 sovereign states.\n",
    "# This is due to the inclusion of dependent territories (e.g., Cocos Islands) \n",
    "# according to the ISO standard. For this exercise, they will be assumed as \n",
    "# valid geographic locations for candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b242a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * However, a small verification will be implemented with the help of the \n",
    "# * pycountry library.\n",
    "\n",
    "for country in df_candidates[\"country\"]:\n",
    "    try:\n",
    "        country = pycountry.countries.get(name=country)\n",
    "    except LookupError:\n",
    "        print(country)\n",
    "        \n",
    "# ! All countries are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ? Consideration is being given to reducing the number of categories to \n",
    "# ? facilitate analysis (e.g., “inter” and “trainee”). \n",
    "\n",
    "df_candidates[\"seniority\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d0daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One finding was that there were records with a YOE of 27 but whose seniority\n",
    "# was trainee. It is understood that the data was generated synthetically, but \n",
    "# in a real context, years of experience are correlated with seniority. During \n",
    "# the transformation stage, logic will be implemented to recalculate seniority \n",
    "# based on years of experience. \n",
    "\n",
    "# TODO: in the transformation phase, change values of seniority by the yoe values\n",
    "\n",
    "df_candidates[(df_candidates[\"yoe\"]>25) & (df_candidates[\"seniority\"] == \"intern\")]\n",
    "\n",
    "# there is 1209 candidates with an \"intern\" seniority and more than 25 yoe, \n",
    "# don't make sense in this context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand the internal consistency of the profiles, we cross-reference \n",
    "# Years of Experience (YOE) with Seniority Level. The plot below reveals a \n",
    "# critical anomaly: the distribution boxes are virtually identical for all \n",
    "# roles (from Intern to Architect). This proves a lack of correlation and \n",
    "# justifies the need for a transformation rule in the ETL process to \n",
    "# recalculate Seniority based on YOE.\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Define a logical order for the x-axis based on the unique values\n",
    "order = [\"trainee\", \"intern\", \"junior\", \"mid-level\", \"senior\", \"lead\", \n",
    "        \"architect\"]\n",
    "\n",
    "sns.boxplot(data=df_candidates, x=\"seniority\", y=\"yoe\", order=order, \n",
    "        hue=\"seniority\", palette=\"Set2\", legend=False)\n",
    "\n",
    "plt.title(\"Anomaly Detection: Years of Experience vs Seniority Level\")\n",
    "plt.xlabel(\"Seniority Level\")\n",
    "plt.ylabel(\"Years of Experience (YOE)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to do here\n",
    "\n",
    "df_candidates[\"technology\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the high cardinality of the technology column, we identify the top 10 \n",
    "# most frequent profiles to understand the volume and focus of the candidate \n",
    "# pool.\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "top_tech = df_candidates[\"technology\"].value_counts().head(10)\n",
    "sns.barplot(x=top_tech.values, y=top_tech.index, hue=top_tech.index, \n",
    "            palette=\"viridis\", legend=False)\n",
    "\n",
    "plt.title(\"Top 10 Technologies Applied For\")\n",
    "plt.xlabel(\"Number of Candidates\")\n",
    "plt.ylabel(\"Technology\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d465b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a real context, usually a candidate with a high score \n",
    "# in code tends to have a lower score in the interview. Since the data is \n",
    "# synthetic, there should be no correlation, so with the code below we should \n",
    "# see a number close to 0.\n",
    "\n",
    "df_candidates[['code challenge score', 'technical interview score']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f1930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand if there is any underlying relationship between our \n",
    "# numeric variables (Years of Experience, Code Challenge Score, and Technical \n",
    "# Interview Score), a correlation matrix was generated. In a synthetic dataset, \n",
    "# its expected that these values to be close to 0, indicating a lack of \n",
    "# correlation.\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Select only numeric columns for correlation\n",
    "numeric_cols = [\"yoe\", \"code challenge score\", \"technical interview score\"]\n",
    "correlation_matrix = df_candidates[numeric_cols].corr()\n",
    "\n",
    "# Create a heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, fmt=\".2f\", linewidths=.5)\n",
    "\n",
    "plt.title(\"Correlation Matrix of Numeric Variables\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
